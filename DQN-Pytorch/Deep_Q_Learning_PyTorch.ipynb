{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qE0tpgUDQCA2"
   },
   "source": [
    "# CSCI566 Lecture 14. PyTorch and Deep Reinforcement Learning Implementation\n",
    "\n",
    "\n",
    "This notebook is for introducing basic usage of PyTorch and an example implementation of deep reinforcement learning algorithm (simple q-learning).\n",
    "\n",
    "\n",
    "It covers introduction to\n",
    "\n",
    "*   PyTorch\n",
    "*   OpenAI gym\n",
    "*   Q-learning implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_jO0H60RiSe"
   },
   "source": [
    "## PyTorch\n",
    "\n",
    "You can find a tutorial at https://bit.ly/60minblitz .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NmH0ndrnipE"
   },
   "outputs": [],
   "source": [
    "# PyTorch \n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spP8Fvaaamrz"
   },
   "source": [
    "### Tensors\n",
    "\n",
    "PyTorch's tensors are similar to numpy's ndarrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "O6doUZOQRl7p",
    "outputId": "c777f5ca-0e57-4319-95ac-2d4bf3efffb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros:  tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "dtype:  torch.float32\n",
      "shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Zero tensor\n",
    "z = torch.zeros(2,3)\n",
    "\n",
    "print('zeros: ', z)\n",
    "print('dtype: ', z.dtype)\n",
    "print('shape: ', z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XpExm4PioQux",
    "outputId": "f94a7cdd-477e-428e-c642-66ae5badf7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones:  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# One tensor\n",
    "o = torch.ones(2,3)\n",
    "\n",
    "print('ones: ', o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PXQM8WKwoR75",
    "outputId": "e8a0f11e-ddea-4280-a027-f0acdc3f8ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random:  tensor([[ 0.7628, -0.4479, -0.0892],\n",
      "        [-0.8782,  1.2657, -0.8894]])\n"
     ]
    }
   ],
   "source": [
    "# Random tensor\n",
    "r = torch.randn(2,3)\n",
    "\n",
    "print('random: ', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "4AJOig6UoR1g",
    "outputId": "0f8c2424-b004-4efb-fbac-981401907ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity:  tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Identity tensor\n",
    "i = torch.eye(3)\n",
    "\n",
    "print('identity: ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "u0TWGTokoRuc",
    "outputId": "d36fc501-013d-467e-d20b-0bff53431767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.1000)\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([5., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Tensor from values, numpy array, list\n",
    "a_scalar = 10.10\n",
    "a = torch.tensor(a_scalar)\n",
    "\n",
    "print(a)\n",
    "\n",
    "b_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor(b_array)\n",
    "\n",
    "print(b) \n",
    "\n",
    "x_list = [5., 6., 6.]\n",
    "x = torch.tensor(x_list)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o1rs6pVroRl4",
    "outputId": "9717a638-070c-414a-ccda-282cc775c70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 6., 6.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Tensor with autograd\n",
    "v = torch.tensor(x_list,requires_grad=True)\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "rPQl23yToRVM",
    "outputId": "fcdcd772-10d7-48d8-e904-a63e6722f6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.100000381469727\n",
      "[5. 6. 6.]\n",
      "[5. 6. 6.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor to scalar\n",
    "print(a.item())\n",
    "\n",
    "\n",
    "# Tensor to numpy array\n",
    "print(x.numpy())\n",
    "\n",
    "\n",
    "#print(v.numpy()) # will generate an error\n",
    "\n",
    "# Tensor with gradient needs to be detached before numpy()\n",
    "print(v.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IalZ8BEygS8c"
   },
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "wnZu1wcRR18o",
    "outputId": "a455333d-89c4-4eea-a9f1-07408f406b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7628, 0.5521, 0.9108],\n",
      "        [0.1218, 2.2657, 0.1106]])\n",
      "tensor([[ 0.7628, -0.4479, -0.0892],\n",
      "        [-0.8782,  1.2657, -0.8894]])\n",
      "tensor([[ 0.7628, -0.4479, -0.0892],\n",
      "        [-0.8782,  1.2657, -0.8894]])\n",
      "tensor([[[1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.]]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Add\n",
    "print(o + r)\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(r * o)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(torch.matmul(r, i))\n",
    "\n",
    "# Reshape\n",
    "print(o.view(3, 2, 1)) # only change view if possible\n",
    "print(o.reshape(3, 2)) # always rearrange values in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Qz2BcAAjKuU"
   },
   "source": [
    "### Gradient\n",
    "The code below shows a simple example of autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pDG6oP-QjMo3",
    "outputId": "1bdcd3bc-68a5-428a-a10d-b43169ef0da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True)\n",
      "tensor(3., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# y = (x - 1)^2 + 2\n",
    "\n",
    "# x = torch.randn(1, requires_grad=True)\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = (x - 1).pow(2) + 2\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4mnkPh-fkQIb",
    "outputId": "6ad9f4c4-b69d-4fb9-c6f0-6c2d468d20b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 1.9800000190734863 2.0\n",
      "2.960400104522705 1.9603999853134155 1.9600000381469727\n",
      "2.922368049621582 1.9411920309066772 1.920799970626831\n",
      "2.8858423233032227 1.9223681688308716 1.8823840618133545\n",
      "2.8507630825042725 1.9039207696914673 1.8447363376617432\n",
      "2.817072868347168 1.8858423233032227 1.8078415393829346\n",
      "2.7847166061401367 1.8681254386901855 1.7716846466064453\n",
      "2.7536418437957764 1.850762963294983 1.736250877380371\n",
      "2.723797559738159 1.8337477445602417 1.7015259265899658\n",
      "2.6951353549957275 1.8170727491378784 1.6674954891204834\n",
      "2.6676077842712402 1.8007313013076782 1.6341454982757568\n",
      "2.6411705017089844 1.7847167253494263 1.6014626026153564\n",
      "2.6157803535461426 1.7690223455429077 1.5694334506988525\n",
      "2.591395378112793 1.7536418437957764 1.5380446910858154\n",
      "2.5679759979248047 1.7385690212249756 1.5072836875915527\n",
      "2.5454840660095215 1.7237976789474487 1.4771380424499512\n",
      "2.523883104324341 1.7093217372894287 1.4475953578948975\n",
      "2.5031373500823975 1.6951353549957275 1.4186434745788574\n",
      "2.483213186264038 1.6812326908111572 1.390270709991455\n",
      "2.464077949523926 1.6676080226898193 1.3624653816223145\n",
      "2.4457004070281982 1.6542558670043945 1.3352160453796387\n",
      "2.4280507564544678 1.6411707401275635 1.308511734008789\n",
      "2.411099910736084 1.6283472776412964 1.282341480255127\n",
      "2.394820213317871 1.6157803535461426 1.2566945552825928\n",
      "2.379185438156128 1.6034647226333618 1.2315607070922852\n",
      "2.3641695976257324 1.591395378112793 1.2069294452667236\n",
      "2.3497486114501953 1.5795674324035645 1.182790756225586\n",
      "2.3358983993530273 1.5679761171340942 1.159134864807129\n",
      "2.322596788406372 1.5566165447235107 1.1359522342681885\n",
      "2.3098220825195312 1.545484185218811 1.1132330894470215\n",
      "2.297553062438965 1.5345745086669922 1.090968370437622\n",
      "2.2857699394226074 1.5238829851150513 1.0691490173339844\n",
      "2.2744534015655518 1.5134053230285645 1.0477659702301025\n",
      "2.263585090637207 1.503137230873108 1.026810646057129\n",
      "2.2531471252441406 1.4930745363235474 1.0062744617462158\n",
      "2.2431225776672363 1.4832130670547485 0.9861490726470947\n",
      "2.233494758605957 1.4735487699508667 0.9664261341094971\n",
      "2.2242484092712402 1.4640778303146362 0.9470975399017334\n",
      "2.2153682708740234 1.454796314239502 0.9281556606292725\n",
      "2.2068395614624023 1.4457004070281982 0.9095926284790039\n",
      "2.1986489295959473 1.436786413192749 0.8914008140563965\n",
      "2.190782308578491 1.4280506372451782 0.873572826385498\n",
      "2.183227300643921 1.4194896221160889 0.8561012744903564\n",
      "2.175971508026123 1.4110997915267944 0.8389792442321777\n",
      "2.1690030097961426 1.4028778076171875 0.8221995830535889\n",
      "2.1623106002807617 1.394820213317871 0.805755615234375\n",
      "2.1558830738067627 1.3869237899780273 0.7896404266357422\n",
      "2.149709939956665 1.3791853189468384 0.7738475799560547\n",
      "2.1437814235687256 1.3716015815734863 0.7583706378936768\n",
      "2.138087749481201 1.3641695976257324 0.7432031631469727\n",
      "2.1326193809509277 1.3568861484527588 0.7283391952514648\n",
      "2.1273677349090576 1.3497483730316162 0.7137722969055176\n",
      "2.122323989868164 1.3427534103393555 0.6994967460632324\n",
      "2.1174798011779785 1.3358983993530273 0.6855068206787109\n",
      "2.112827777862549 1.3291804790496826 0.6717967987060547\n",
      "2.1083598136901855 1.3225969076156616 0.6583609580993652\n",
      "2.1040687561035156 1.3161449432373047 0.6451938152313232\n",
      "2.099947690963745 1.3098220825195312 0.6322898864746094\n",
      "2.09598970413208 1.3036255836486816 0.6196441650390625\n",
      "2.092188596725464 1.2975530624389648 0.6072511672973633\n",
      "2.0885379314422607 1.2916020154953003 0.5951061248779297\n",
      "2.085031747817993 1.2857699394226074 0.5832040309906006\n",
      "2.081664562225342 1.2800545692443848 0.5715398788452148\n",
      "2.078430652618408 1.2744535207748413 0.5601091384887695\n",
      "2.075324773788452 1.268964409828186 0.5489070415496826\n",
      "2.0723419189453125 1.263585090637207 0.5379288196563721\n",
      "2.069477081298828 1.2583134174346924 0.5271701812744141\n",
      "2.066725730895996 1.2531471252441406 0.5166268348693848\n",
      "2.0640835762023926 1.2480841875076294 0.5062942504882812\n",
      "2.0615458488464355 1.2431224584579468 0.4961683750152588\n",
      "2.0591084957122803 1.23826003074646 0.48624491691589355\n",
      "2.0567679405212402 1.2334948778152466 0.4765200614929199\n",
      "2.0545198917388916 1.2288249731063843 0.46698975563049316\n",
      "2.052360773086548 1.2242485284805298 0.45764994621276855\n",
      "2.0502874851226807 1.2197635173797607 0.44849705696105957\n",
      "2.0482959747314453 1.2153682708740234 0.4395270347595215\n",
      "2.0463833808898926 1.211060881614685 0.4307365417480469\n",
      "2.044546604156494 1.206839680671692 0.4221217632293701\n",
      "2.0427825450897217 1.2027028799057007 0.4136793613433838\n",
      "2.041088342666626 1.1986488103866577 0.40540575981140137\n",
      "2.039461374282837 1.1946758031845093 0.39729762077331543\n",
      "2.0378987789154053 1.1907823085784912 0.38935160636901855\n",
      "2.036397933959961 1.1869666576385498 0.3815646171569824\n",
      "2.034956455230713 1.183227300643921 0.3739333152770996\n",
      "2.033572196960449 1.1795628070831299 0.3664546012878418\n",
      "2.032242774963379 1.175971508026123 0.35912561416625977\n",
      "2.03096604347229 1.1724520921707153 0.3519430160522461\n",
      "2.0297396183013916 1.1690030097961426 0.34490418434143066\n",
      "2.028562068939209 1.1656229496002197 0.33800601959228516\n",
      "2.027431011199951 1.1623104810714722 0.33124589920043945\n",
      "2.0263447761535645 1.1590642929077148 0.32462096214294434\n",
      "2.025301456451416 1.1558829545974731 0.3181285858154297\n",
      "2.024299383163452 1.1527652740478516 0.3117659091949463\n",
      "2.0233371257781982 1.149709939956665 0.3055305480957031\n",
      "2.0224130153656006 1.146715760231018 0.2994198799133301\n",
      "2.0215256214141846 1.1437814235687256 0.29343152046203613\n",
      "2.0206730365753174 1.140905737876892 0.28756284713745117\n",
      "2.0198545455932617 1.1380876302719116 0.2818114757537842\n",
      "2.0190682411193848 1.1353259086608887 0.27617526054382324\n",
      "2.01831316947937 1.1326193809509277 0.27065181732177734\n",
      "2.017587900161743 1.1299669742584229 0.26523876190185547\n",
      "2.0168914794921875 1.127367615699768 0.2599339485168457\n",
      "2.0162224769592285 1.1248202323913574 0.25473523139953613\n",
      "2.015580177307129 1.1223238706588745 0.24964046478271484\n",
      "2.014963150024414 1.1198773384094238 0.24464774131774902\n",
      "2.0143706798553467 1.1174798011779785 0.23975467681884766\n",
      "2.0138015747070312 1.1151301860809326 0.23495960235595703\n",
      "2.0132548809051514 1.1128275394439697 0.23026037216186523\n",
      "2.012730121612549 1.110571026802063 0.22565507888793945\n",
      "2.012225866317749 1.1083595752716064 0.22114205360412598\n",
      "2.011741876602173 1.1061923503875732 0.2167191505432129\n",
      "2.0112767219543457 1.1040685176849365 0.21238470077514648\n",
      "2.0108301639556885 1.1019871234893799 0.20813703536987305\n",
      "2.010401487350464 1.0999473333358765 0.20397424697875977\n",
      "2.0099895000457764 1.097948431968689 0.19989466667175293\n",
      "2.009593963623047 1.095989465713501 0.19589686393737793\n",
      "2.009213924407959 1.0940697193145752 0.19197893142700195\n",
      "2.0088491439819336 1.0921883583068848 0.1881394386291504\n",
      "2.0084986686706543 1.0903445482254028 0.18437671661376953\n",
      "2.008162021636963 1.0885376930236816 0.18068909645080566\n",
      "2.0078389644622803 1.0867669582366943 0.17707538604736328\n",
      "2.00752854347229 1.0850316286087036 0.17353391647338867\n",
      "2.007230281829834 1.0833309888839722 0.17006325721740723\n",
      "2.006943941116333 1.0816643238067627 0.16666197776794434\n",
      "2.006669044494629 1.0800310373306274 0.1633286476135254\n",
      "2.0064048767089844 1.078430414199829 0.16006207466125488\n",
      "2.0061514377593994 1.07686185836792 0.1568608283996582\n",
      "2.0059077739715576 1.0753246545791626 0.15372371673583984\n",
      "2.005673885345459 1.0738182067871094 0.1506493091583252\n",
      "2.005449056625366 1.072341799736023 0.14763641357421875\n",
      "2.0052332878112793 1.0708949565887451 0.1446835994720459\n",
      "2.00502610206604 1.0694770812988281 0.14178991317749023\n",
      "2.0048270225524902 1.0680875778198242 0.13895416259765625\n",
      "2.004635810852051 1.0667258501052856 0.13617515563964844\n",
      "2.0044522285461426 1.0653913021087646 0.1334517002105713\n",
      "2.0042760372161865 1.064083456993103 0.1307826042175293\n",
      "2.0041067600250244 1.0628018379211426 0.12816691398620605\n",
      "2.003944158554077 1.0615458488464355 0.12560367584228516\n",
      "2.0037879943847656 1.0603148937225342 0.1230916976928711\n",
      "2.0036377906799316 1.0591086149215698 0.12062978744506836\n",
      "2.0034937858581543 1.0579264163970947 0.11821722984313965\n",
      "2.0033555030822754 1.0567679405212402 0.11585283279418945\n",
      "2.003222703933716 1.0556325912475586 0.11353588104248047\n",
      "2.0030949115753174 1.0545198917388916 0.11126518249511719\n",
      "2.002972364425659 1.0534294843673706 0.1090397834777832\n",
      "2.002854824066162 1.0523608922958374 0.10685896873474121\n",
      "2.002741575241089 1.0513136386871338 0.1047217845916748\n",
      "2.0026330947875977 1.0502873659133911 0.10262727737426758\n",
      "2.0025289058685303 1.0492815971374512 0.10057473182678223\n",
      "2.0024287700653076 1.0482959747314453 0.09856319427490234\n",
      "2.0023324489593506 1.0473300218582153 0.09659194946289062\n",
      "2.0022401809692383 1.0463833808898926 0.09466004371643066\n",
      "2.0021514892578125 1.0454556941986084 0.09276676177978516\n",
      "2.002066135406494 1.0445466041564941 0.0909113883972168\n",
      "2.0019843578338623 1.0436556339263916 0.08909320831298828\n",
      "2.001905918121338 1.0427825450897217 0.0873112678527832\n",
      "2.0018303394317627 1.0419268608093262 0.08556509017944336\n",
      "2.001757860183716 1.041088342666626 0.08385372161865234\n",
      "2.001688241958618 1.0402666330337524 0.08217668533325195\n",
      "2.0016214847564697 1.0394612550735474 0.08053326606750488\n",
      "2.0015571117401123 1.0386719703674316 0.07892251014709473\n",
      "2.001495599746704 1.0378985404968262 0.07734394073486328\n",
      "2.001436233520508 1.0371406078338623 0.07579708099365234\n",
      "2.0013794898986816 1.0363978147506714 0.07428121566772461\n",
      "2.0013248920440674 1.0356698036193848 0.07279562950134277\n",
      "2.001272439956665 1.034956455230713 0.07133960723876953\n",
      "2.0012218952178955 1.0342572927474976 0.06991291046142578\n",
      "2.001173496246338 1.0335721969604492 0.06851458549499512\n",
      "2.001127004623413 1.0329008102416992 0.06714439392089844\n",
      "2.001082420349121 1.032242774963379 0.06580162048339844\n",
      "2.001039505004883 1.0315979719161987 0.06448554992675781\n",
      "2.0009984970092773 1.03096604347229 0.06319594383239746\n",
      "2.0009589195251465 1.0303467512130737 0.06193208694458008\n",
      "2.0009210109710693 1.0297398567199707 0.06069350242614746\n",
      "2.000884532928467 1.0291450023651123 0.059479713439941406\n",
      "2.000849485397339 1.028562068939209 0.05829000473022461\n",
      "2.0008158683776855 1.0279908180236816 0.05712413787841797\n",
      "2.0007834434509277 1.0274310111999512 0.05598163604736328\n",
      "2.0007524490356445 1.0268824100494385 0.054862022399902344\n",
      "2.000722646713257 1.0263447761535645 0.05376482009887695\n",
      "2.0006940364837646 1.02581787109375 0.052689552307128906\n",
      "2.000666618347168 1.025301456451416 0.0516357421875\n",
      "2.0006401538848877 1.024795413017273 0.05060291290283203\n",
      "2.000614881515503 1.0242995023727417 0.0495908260345459\n",
      "2.0005905628204346 1.0238134860992432 0.0485990047454834\n",
      "2.0005671977996826 1.0233372449874878 0.04762697219848633\n",
      "2.000544548034668 1.0228705406188965 0.046674489974975586\n",
      "2.000523090362549 1.0224131345748901 0.04574108123779297\n",
      "2.000502347946167 1.0219649076461792 0.04482626914978027\n",
      "2.0004825592041016 1.0215256214141846 0.0439298152923584\n",
      "2.0004632472991943 1.0210951566696167 0.04305124282836914\n",
      "2.0004448890686035 1.0206732749938965 0.0421903133392334\n",
      "2.000427484512329 1.0202598571777344 0.04134654998779297\n",
      "2.000410556793213 1.0198546648025513 0.04051971435546875\n",
      "2.000394105911255 1.0194575786590576 0.03970932960510254\n",
      "2.0003786087036133 1.0190684795379639 0.038915157318115234\n",
      "2.00036358833313 1.018687129020691 0.038136959075927734\n",
      "2.000349283218384 1.0183134078979492 0.037374258041381836\n",
      "2.000335454940796 1.0179471969604492 0.03662681579589844\n",
      "2.000322103500366 1.0175882577896118 0.03589439392089844\n",
      "2.0003092288970947 1.0172364711761475 0.03517651557922363\n",
      "2.0002970695495605 1.0168917179107666 0.03447294235229492\n",
      "2.0002853870391846 1.0165538787841797 0.0337834358215332\n",
      "2.0002739429473877 1.0162228345870972 0.033107757568359375\n",
      "2.000263214111328 1.01589834690094 0.032445669174194336\n",
      "2.0002527236938477 1.015580415725708 0.03179669380187988\n",
      "2.0002427101135254 1.0152688026428223 0.031160831451416016\n",
      "2.0002331733703613 1.0149633884429932 0.03053760528564453\n",
      "2.0002238750457764 1.0146641731262207 0.029926776885986328\n",
      "2.0002150535583496 1.0143709182739258 0.029328346252441406\n",
      "2.000206470489502 1.0140835046768188 0.028741836547851562\n",
      "2.0001983642578125 1.0138018131256104 0.028167009353637695\n",
      "2.000190496444702 1.0135257244110107 0.027603626251220703\n",
      "2.000182867050171 1.01325523853302 0.027051448822021484\n",
      "2.000175714492798 1.012990117073059 0.02651047706604004\n",
      "2.000168800354004 1.012730360031128 0.025980234146118164\n",
      "2.000162124633789 1.0124757289886475 0.02546072006225586\n",
      "2.0001556873321533 1.0122262239456177 0.024951457977294922\n",
      "2.0001494884490967 1.011981725692749 0.02445244789123535\n",
      "2.000143527984619 1.011742115020752 0.023963451385498047\n",
      "2.0001378059387207 1.011507272720337 0.023484230041503906\n",
      "2.0001323223114014 1.0112770795822144 0.023014545440673828\n",
      "2.000127077102661 1.0110515356063843 0.02255415916442871\n",
      "2.0001220703125 1.0108305215835571 0.022103071212768555\n",
      "2.000117301940918 1.0106139183044434 0.021661043167114258\n",
      "2.000112771987915 1.0104016065597534 0.02122783660888672\n",
      "2.000108242034912 1.0101935863494873 0.020803213119506836\n",
      "2.0001039505004883 1.0099897384643555 0.02038717269897461\n",
      "2.0000998973846436 1.0097899436950684 0.019979476928710938\n",
      "2.000095844268799 1.009594202041626 0.01957988739013672\n",
      "2.000092029571533 1.0094022750854492 0.019188404083251953\n",
      "2.0000884532928467 1.0092142820358276 0.018804550170898438\n",
      "2.00008487701416 1.0090299844741821 0.018428564071655273\n",
      "2.0000815391540527 1.0088493824005127 0.018059968948364258\n",
      "2.0000782012939453 1.0086723566055298 0.01769876480102539\n",
      "2.000075101852417 1.0084989070892334 0.01734471321105957\n",
      "2.0000722408294678 1.008328914642334 0.016997814178466797\n",
      "2.0000693798065186 1.0081623792648315 0.01665782928466797\n",
      "2.0000665187835693 1.0079991817474365 0.016324758529663086\n",
      "2.000063896179199 1.0078392028808594 0.015998363494873047\n",
      "2.000061511993408 1.0076824426651 0.01567840576171875\n",
      "2.000059127807617 1.0075287818908691 0.015364885330200195\n",
      "2.000056743621826 1.0073782205581665 0.015057563781738281\n",
      "2.000054359436035 1.0072306394577026 0.014756441116333008\n",
      "2.0000522136688232 1.0070860385894775 0.014461278915405273\n",
      "2.0000503063201904 1.0069442987442017 0.014172077178955078\n",
      "2.0000481605529785 1.006805419921875 0.01388859748840332\n",
      "2.0000462532043457 1.006669282913208 0.01361083984375\n",
      "2.000044584274292 1.0065358877182007 0.013338565826416016\n",
      "2.000042676925659 1.0064051151275635 0.013071775436401367\n",
      "2.0000410079956055 1.0062769651412964 0.012810230255126953\n",
      "2.0000393390655518 1.0061514377593994 0.012553930282592773\n",
      "2.000037908554077 1.006028413772583 0.012302875518798828\n",
      "2.0000362396240234 1.0059078931808472 0.012056827545166016\n",
      "2.000034809112549 1.0057897567749023 0.011815786361694336\n",
      "2.0000336170196533 1.0056740045547485 0.011579513549804688\n",
      "2.0000321865081787 1.0055605173110962 0.01134800910949707\n",
      "2.000030994415283 1.0054492950439453 0.011121034622192383\n",
      "2.0000298023223877 1.005340337753296 0.010898590087890625\n",
      "2.000028610229492 1.0052335262298584 0.010680675506591797\n",
      "2.0000274181365967 1.0051288604736328 0.010467052459716797\n",
      "2.000026226043701 1.0050263404846191 0.010257720947265625\n",
      "2.0000252723693848 1.0049258470535278 0.010052680969238281\n",
      "2.0000243186950684 1.0048273801803589 0.009851694107055664\n",
      "2.000023365020752 1.0047308206558228 0.009654760360717773\n",
      "2.0000224113464355 1.0046361684799194 0.009461641311645508\n",
      "2.000021457672119 1.004543423652649 0.009272336959838867\n",
      "2.000020742416382 1.0044525861740112 0.009086847305297852\n",
      "2.0000197887420654 1.0043635368347168 0.008905172348022461\n",
      "2.000019073486328 1.0042762756347656 0.008727073669433594\n",
      "2.000018358230591 1.0041908025741577 0.00855255126953125\n",
      "2.0000176429748535 1.0041069984436035 0.00838160514831543\n",
      "2.000016927719116 1.004024863243103 0.008213996887207031\n",
      "2.000016212463379 1.0039443969726562 0.008049726486206055\n",
      "2.0000154972076416 1.0038654804229736 0.0078887939453125\n",
      "2.0000150203704834 1.0037881135940552 0.007730960845947266\n",
      "2.000014305114746 1.0037122964859009 0.0075762271881103516\n",
      "2.000013828277588 1.0036380290985107 0.007424592971801758\n",
      "2.0000133514404297 1.0035653114318848 0.007276058197021484\n",
      "2.0000126361846924 1.0034940242767334 0.007130622863769531\n",
      "2.000012159347534 1.0034241676330566 0.006988048553466797\n",
      "2.000011682510376 1.0033557415008545 0.006848335266113281\n",
      "2.0000112056732178 1.0032886266708374 0.006711483001708984\n",
      "2.0000107288360596 1.0032228231430054 0.006577253341674805\n",
      "2.0000104904174805 1.0031583309173584 0.006445646286010742\n",
      "2.0000100135803223 1.0030951499938965 0.006316661834716797\n",
      "2.000009536743164 1.0030332803726196 0.006190299987792969\n",
      "2.000009298324585 1.0029726028442383 0.006066560745239258\n",
      "2.0000088214874268 1.0029131174087524 0.0059452056884765625\n",
      "2.0000085830688477 1.002854824066162 0.005826234817504883\n",
      "2.0000081062316895 1.0027977228164673 0.005709648132324219\n",
      "2.0000078678131104 1.002741813659668 0.00559544563293457\n",
      "2.0000076293945312 1.0026869773864746 0.0054836273193359375\n",
      "2.000007152557373 1.0026332139968872 0.005373954772949219\n",
      "2.000006914138794 1.0025805234909058 0.005266427993774414\n",
      "2.000006675720215 1.0025289058685303 0.0051610469818115234\n",
      "2.0000064373016357 1.0024783611297607 0.005057811737060547\n",
      "2.0000061988830566 1.0024287700653076 0.004956722259521484\n",
      "2.0000059604644775 1.0023802518844604 0.004857540130615234\n",
      "2.0000057220458984 1.0023326873779297 0.0047605037689208984\n",
      "2.0000054836273193 1.0022860765457153 0.004665374755859375\n",
      "2.0000052452087402 1.0022403001785278 0.004572153091430664\n",
      "2.000005006790161 1.0021954774856567 0.004480600357055664\n",
      "2.000004768371582 1.002151608467102 0.0043909549713134766\n",
      "2.000004529953003 1.0021085739135742 0.0043032169342041016\n",
      "2.000004529953003 1.0020663738250732 0.0042171478271484375\n",
      "2.000004291534424 1.0020250082015991 0.004132747650146484\n",
      "2.0000040531158447 1.0019844770431519 0.004050016403198242\n",
      "2.0000040531158447 1.0019447803497314 0.003968954086303711\n",
      "2.0000038146972656 1.001905918121338 0.0038895606994628906\n",
      "2.0000035762786865 1.0018677711486816 0.0038118362426757812\n",
      "2.0000035762786865 1.0018304586410522 0.0037355422973632812\n",
      "2.0000033378601074 1.0017938613891602 0.003660917282104492\n",
      "2.0000030994415283 1.0017579793930054 0.0035877227783203125\n",
      "2.0000030994415283 1.001722812652588 0.003515958786010742\n",
      "2.000002861022949 1.0016883611679077 0.0034456253051757812\n",
      "2.000002861022949 1.0016546249389648 0.0033767223358154297\n",
      "2.00000262260437 1.0016214847564697 0.0033092498779296875\n",
      "2.00000262260437 1.001589059829712 0.003242969512939453\n",
      "2.00000262260437 1.0015572309494019 0.003178119659423828\n",
      "2.000002384185791 1.001526117324829 0.003114461898803711\n",
      "2.000002384185791 1.001495599746704 0.003052234649658203\n",
      "2.000002145767212 1.0014656782150269 0.002991199493408203\n",
      "2.000002145767212 1.0014363527297974 0.002931356430053711\n",
      "2.000002145767212 1.0014076232910156 0.0028727054595947266\n",
      "2.000001907348633 1.0013794898986816 0.00281524658203125\n",
      "2.000001907348633 1.0013519525527954 0.0027589797973632812\n",
      "2.000001907348633 1.0013248920440674 0.0027039051055908203\n",
      "2.0000016689300537 1.001298427581787 0.0026497840881347656\n",
      "2.0000016689300537 1.001272439956665 0.0025968551635742188\n",
      "2.0000016689300537 1.0012470483779907 0.002544879913330078\n",
      "2.0000016689300537 1.0012221336364746 0.0024940967559814453\n",
      "2.0000014305114746 1.0011976957321167 0.0024442672729492188\n",
      "2.0000014305114746 1.001173734664917 0.0023953914642333984\n",
      "2.0000014305114746 1.0011502504348755 0.0023474693298339844\n",
      "2.0000014305114746 1.0011272430419922 0.0023005008697509766\n",
      "2.0000011920928955 1.001104712486267 0.002254486083984375\n",
      "2.0000011920928955 1.0010826587677002 0.0022094249725341797\n",
      "2.0000011920928955 1.001060962677002 0.0021653175354003906\n",
      "2.0000011920928955 1.001039743423462 0.0021219253540039062\n",
      "2.0000011920928955 1.00101900100708 0.002079486846923828\n",
      "2.0000009536743164 1.000998616218567 0.0020380020141601562\n",
      "2.0000009536743164 1.0009785890579224 0.001997232437133789\n",
      "2.0000009536743164 1.000959038734436 0.0019571781158447266\n",
      "2.0000009536743164 1.0009398460388184 0.0019180774688720703\n",
      "2.0000009536743164 1.0009210109710693 0.0018796920776367188\n",
      "2.0000009536743164 1.000902533531189 0.0018420219421386719\n",
      "2.0000007152557373 1.0008845329284668 0.0018050670623779297\n",
      "2.0000007152557373 1.0008668899536133 0.0017690658569335938\n",
      "2.0000007152557373 1.0008496046066284 0.0017337799072265625\n",
      "2.0000007152557373 1.0008325576782227 0.001699209213256836\n",
      "2.0000007152557373 1.0008158683776855 0.0016651153564453125\n",
      "2.0000007152557373 1.000799536705017 0.0016317367553710938\n",
      "2.0000007152557373 1.0007835626602173 0.0015990734100341797\n",
      "2.0000007152557373 1.0007679462432861 0.0015671253204345703\n",
      "2.000000476837158 1.000752568244934 0.0015358924865722656\n",
      "2.000000476837158 1.0007375478744507 0.001505136489868164\n",
      "2.000000476837158 1.0007227659225464 0.0014750957489013672\n",
      "2.000000476837158 1.0007083415985107 0.0014455318450927734\n",
      "2.000000476837158 1.0006941556930542 0.0014166831970214844\n",
      "2.000000476837158 1.0006803274154663 0.0013883113861083984\n",
      "2.000000476837158 1.0006667375564575 0.0013606548309326172\n",
      "2.000000476837158 1.0006533861160278 0.001333475112915039\n",
      "2.000000476837158 1.0006402730941772 0.001306772232055664\n",
      "2.000000476837158 1.0006275177001953 0.0012805461883544922\n",
      "2.000000476837158 1.0006150007247925 0.001255035400390625\n",
      "2.000000476837158 1.0006027221679688 0.001230001449584961\n",
      "2.000000476837158 1.0005906820297241 0.0012054443359375\n",
      "2.000000238418579 1.0005788803100586 0.0011813640594482422\n",
      "2.000000238418579 1.0005673170089722 0.0011577606201171875\n",
      "2.000000238418579 1.0005559921264648 0.001134634017944336\n",
      "2.000000238418579 1.0005449056625366 0.0011119842529296875\n",
      "2.000000238418579 1.0005340576171875 0.0010898113250732422\n",
      "2.000000238418579 1.000523328781128 0.001068115234375\n",
      "2.000000238418579 1.0005128383636475 0.0010466575622558594\n",
      "2.000000238418579 1.000502586364746 0.0010256767272949219\n",
      "2.000000238418579 1.0004925727844238 0.0010051727294921875\n",
      "2.000000238418579 1.0004826784133911 0.0009851455688476562\n",
      "2.000000238418579 1.0004730224609375 0.0009653568267822266\n",
      "2.000000238418579 1.000463604927063 0.000946044921875\n",
      "2.000000238418579 1.000454306602478 0.0009272098541259766\n",
      "2.000000238418579 1.0004452466964722 0.0009086132049560547\n",
      "2.000000238418579 1.0004363059997559 0.0008904933929443359\n",
      "2.000000238418579 1.0004276037216187 0.0008726119995117188\n",
      "2.000000238418579 1.000419020652771 0.0008552074432373047\n",
      "2.000000238418579 1.0004106760025024 0.0008380413055419922\n",
      "2.000000238418579 1.0004024505615234 0.0008213520050048828\n",
      "2.000000238418579 1.000394344329834 0.000804901123046875\n",
      "2.000000238418579 1.0003864765167236 0.0007886886596679688\n",
      "2.000000238418579 1.0003787279129028 0.0007729530334472656\n",
      "2.000000238418579 1.0003710985183716 0.0007574558258056641\n",
      "2.000000238418579 1.0003637075424194 0.0007421970367431641\n",
      "2.000000238418579 1.0003564357757568 0.0007274150848388672\n",
      "2.000000238418579 1.0003492832183838 0.0007128715515136719\n",
      "2.000000238418579 1.0003422498703003 0.0006985664367675781\n",
      "2.0 1.000335454940796 0.0006844997406005859\n",
      "2.0 1.000328779220581 0.0006709098815917969\n",
      "2.0 1.0003222227096558 0.0006575584411621094\n",
      "2.0 1.00031578540802 0.0006444454193115234\n",
      "2.0 1.0003094673156738 0.0006315708160400391\n",
      "2.0 1.0003032684326172 0.0006189346313476562\n",
      "2.0 1.00029718875885 0.000606536865234375\n",
      "2.0 1.0002912282943726 0.0005943775177001953\n",
      "2.0 1.0002853870391846 0.0005824565887451172\n",
      "2.0 1.0002796649932861 0.0005707740783691406\n",
      "2.0 1.0002740621566772 0.0005593299865722656\n",
      "2.0 1.000268578529358 0.0005481243133544922\n",
      "2.0 1.0002632141113281 0.0005371570587158203\n",
      "2.0 1.000257968902588 0.00052642822265625\n",
      "2.0 1.0002528429031372 0.0005159378051757812\n",
      "2.0 1.000247836112976 0.0005056858062744141\n",
      "2.0 1.000242829322815 0.0004956722259521484\n",
      "2.0 1.0002379417419434 0.0004856586456298828\n",
      "2.0 1.0002331733703613 0.00047588348388671875\n",
      "2.0 1.0002285242080688 0.00046634674072265625\n",
      "2.0 1.000223994255066 0.0004570484161376953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 1.000219464302063 0.00044798851013183594\n",
      "2.0 1.0002150535583496 0.00043892860412597656\n",
      "2.0 1.0002107620239258 0.00043010711669921875\n",
      "2.0 1.0002065896987915 0.0004215240478515625\n",
      "2.0 1.0002024173736572 0.0004131793975830078\n",
      "2.0 1.0001983642578125 0.0004048347473144531\n",
      "2.0 1.0001944303512573 0.000396728515625\n",
      "2.0 1.0001904964447021 0.00038886070251464844\n",
      "2.0 1.0001866817474365 0.0003809928894042969\n",
      "2.0 1.0001829862594604 0.0003733634948730469\n",
      "2.0 1.0001792907714844 0.00036597251892089844\n",
      "2.0 1.0001757144927979 0.00035858154296875\n",
      "2.0 1.0001722574234009 0.0003514289855957031\n",
      "2.0 1.000168800354004 0.0003445148468017578\n",
      "2.0 1.0001654624938965 0.0003376007080078125\n",
      "2.0 1.000162124633789 0.00033092498779296875\n",
      "2.0 1.0001589059829712 0.000324249267578125\n",
      "2.0 1.0001556873321533 0.0003178119659423828\n",
      "2.0 1.000152587890625 0.0003113746643066406\n",
      "2.0 1.0001494884490967 0.00030517578125\n",
      "2.0 1.000146508216858 0.0002989768981933594\n",
      "2.0 1.0001435279846191 0.0002930164337158203\n",
      "2.0 1.00014066696167 0.00028705596923828125\n",
      "2.0 1.0001378059387207 0.00028133392333984375\n",
      "2.0 1.000135064125061 0.00027561187744140625\n",
      "2.0 1.0001323223114014 0.0002701282501220703\n",
      "2.0 1.0001296997070312 0.0002646446228027344\n",
      "2.0 1.0001270771026611 0.0002593994140625\n",
      "2.0 1.0001245737075806 0.0002541542053222656\n",
      "2.0 1.0001220703125 0.0002491474151611328\n",
      "2.0 1.000119686126709 0.000244140625\n",
      "2.0 1.000117301940918 0.00023937225341796875\n",
      "2.0 1.000114917755127 0.0002346038818359375\n",
      "2.0 1.0001126527786255 0.00022983551025390625\n",
      "2.0 1.000110387802124 0.00022530555725097656\n",
      "2.0 1.0001081228256226 0.00022077560424804688\n",
      "2.0 1.0001059770584106 0.0002162456512451172\n",
      "2.0 1.0001038312911987 0.00021195411682128906\n",
      "2.0 1.0001018047332764 0.00020766258239746094\n",
      "2.0 1.000099778175354 0.00020360946655273438\n",
      "2.0 1.0000977516174316 0.0001995563507080078\n",
      "2.0 1.0000958442687988 0.00019550323486328125\n",
      "2.0 1.000093936920166 0.00019168853759765625\n",
      "2.0 1.0000920295715332 0.00018787384033203125\n",
      "2.0 1.00009024143219 0.00018405914306640625\n",
      "2.0 1.0000884532928467 0.0001804828643798828\n",
      "2.0 1.0000866651535034 0.00017690658569335938\n",
      "2.0 1.0000848770141602 0.00017333030700683594\n",
      "2.0 1.0000832080841064 0.0001697540283203125\n",
      "2.0 1.0000815391540527 0.00016641616821289062\n",
      "2.0 1.000079870223999 0.00016307830810546875\n",
      "2.0 1.0000783205032349 0.00015974044799804688\n",
      "2.0 1.0000767707824707 0.00015664100646972656\n",
      "2.0 1.0000752210617065 0.00015354156494140625\n",
      "2.0 1.0000736713409424 0.00015044212341308594\n",
      "2.0 1.0000722408294678 0.00014734268188476562\n",
      "2.0 1.0000708103179932 0.00014448165893554688\n",
      "2.0 1.0000693798065186 0.00014162063598632812\n",
      "2.0 1.000067949295044 0.00013875961303710938\n",
      "2.0 1.0000666379928589 0.00013589859008789062\n",
      "2.0 1.0000653266906738 0.00013327598571777344\n",
      "2.0 1.0000640153884888 0.00013065338134765625\n",
      "2.0 1.0000627040863037 0.00012803077697753906\n",
      "2.0 1.0000613927841187 0.00012540817260742188\n",
      "2.0 1.0000602006912231 0.0001227855682373047\n",
      "2.0 1.0000590085983276 0.00012040138244628906\n",
      "2.0 1.0000578165054321 0.00011801719665527344\n",
      "2.0 1.0000566244125366 0.00011563301086425781\n",
      "2.0 1.0000555515289307 0.00011324882507324219\n",
      "2.0 1.0000544786453247 0.00011110305786132812\n",
      "2.0 1.0000534057617188 0.00010895729064941406\n",
      "2.0 1.0000523328781128 0.0001068115234375\n",
      "2.0 1.0000512599945068 0.00010466575622558594\n",
      "2.0 1.0000501871109009 0.00010251998901367188\n",
      "2.0 1.0000492334365845 0.00010037422180175781\n",
      "2.0 1.000048279762268 9.846687316894531e-05\n",
      "2.0 1.0000473260879517 9.655952453613281e-05\n",
      "2.0 1.0000463724136353 9.465217590332031e-05\n",
      "2.0 1.0000454187393188 9.274482727050781e-05\n",
      "2.0 1.0000444650650024 9.083747863769531e-05\n",
      "2.0 1.0000436305999756 8.893013000488281e-05\n",
      "2.0 1.0000427961349487 8.726119995117188e-05\n",
      "2.0 1.0000419616699219 8.559226989746094e-05\n",
      "2.0 1.000041127204895 8.392333984375e-05\n",
      "2.0 1.0000402927398682 8.225440979003906e-05\n",
      "2.0 1.0000394582748413 8.058547973632812e-05\n",
      "2.0 1.0000386238098145 7.891654968261719e-05\n",
      "2.0 1.0000379085540771 7.724761962890625e-05\n",
      "2.0 1.0000371932983398 7.581710815429688e-05\n",
      "2.0 1.0000364780426025 7.43865966796875e-05\n",
      "2.0 1.0000357627868652 7.295608520507812e-05\n",
      "2.0 1.000035047531128 7.152557373046875e-05\n",
      "2.0 1.0000343322753906 7.009506225585938e-05\n",
      "2.0 1.0000336170196533 6.866455078125e-05\n",
      "2.0 1.000032901763916 6.723403930664062e-05\n",
      "2.0 1.0000321865081787 6.580352783203125e-05\n",
      "2.0 1.000031590461731 6.437301635742188e-05\n",
      "2.0 1.0000309944152832 6.318092346191406e-05\n",
      "2.0 1.0000303983688354 6.198883056640625e-05\n",
      "2.0 1.0000298023223877 6.079673767089844e-05\n",
      "2.0 1.00002920627594 5.9604644775390625e-05\n",
      "2.0 1.0000286102294922 5.841255187988281e-05\n",
      "2.0 1.0000280141830444 5.7220458984375e-05\n",
      "2.0 1.0000274181365967 5.602836608886719e-05\n",
      "2.0 1.000026822090149 5.4836273193359375e-05\n",
      "2.0 1.0000262260437012 5.364418029785156e-05\n",
      "2.0 1.000025749206543 5.245208740234375e-05\n",
      "2.0 1.0000252723693848 5.14984130859375e-05\n",
      "2.0 1.0000247955322266 5.054473876953125e-05\n",
      "2.0 1.0000243186950684 4.9591064453125e-05\n",
      "2.0 1.0000238418579102 4.863739013671875e-05\n",
      "2.0 1.000023365020752 4.76837158203125e-05\n",
      "2.0 1.0000228881835938 4.673004150390625e-05\n",
      "2.0 1.0000224113464355 4.57763671875e-05\n",
      "2.0 1.0000219345092773 4.482269287109375e-05\n",
      "2.0 1.0000214576721191 4.38690185546875e-05\n",
      "2.0 1.000020980834961 4.291534423828125e-05\n",
      "2.0 1.0000205039978027 4.1961669921875e-05\n",
      "2.0 1.000020146369934 4.100799560546875e-05\n",
      "2.0 1.0000197887420654 4.029273986816406e-05\n",
      "2.0 1.0000194311141968 3.9577484130859375e-05\n",
      "2.0 1.0000190734863281 3.886222839355469e-05\n",
      "2.0 1.0000187158584595 3.814697265625e-05\n",
      "2.0 1.0000183582305908 3.743171691894531e-05\n",
      "2.0 1.0000180006027222 3.6716461181640625e-05\n",
      "2.0 1.0000176429748535 3.600120544433594e-05\n",
      "2.0 1.0000172853469849 3.528594970703125e-05\n",
      "2.0 1.0000169277191162 3.457069396972656e-05\n",
      "2.0 1.0000165700912476 3.3855438232421875e-05\n",
      "2.0 1.000016212463379 3.314018249511719e-05\n",
      "2.0 1.0000158548355103 3.24249267578125e-05\n",
      "2.0 1.0000154972076416 3.170967102050781e-05\n",
      "2.0 1.000015139579773 3.0994415283203125e-05\n",
      "2.0 1.0000147819519043 3.0279159545898438e-05\n",
      "2.0 1.0000145435333252 2.956390380859375e-05\n",
      "2.0 1.000014305114746 2.9087066650390625e-05\n",
      "2.0 1.000014066696167 2.86102294921875e-05\n",
      "2.0 1.000013828277588 2.8133392333984375e-05\n",
      "2.0 1.0000135898590088 2.765655517578125e-05\n",
      "2.0 1.0000133514404297 2.7179718017578125e-05\n",
      "2.0 1.0000131130218506 2.6702880859375e-05\n",
      "2.0 1.0000128746032715 2.6226043701171875e-05\n",
      "2.0 1.0000126361846924 2.574920654296875e-05\n",
      "2.0 1.0000123977661133 2.5272369384765625e-05\n",
      "2.0 1.0000121593475342 2.47955322265625e-05\n",
      "2.0 1.000011920928955 2.4318695068359375e-05\n",
      "2.0 1.000011682510376 2.384185791015625e-05\n",
      "2.0 1.0000114440917969 2.3365020751953125e-05\n",
      "2.0 1.0000112056732178 2.288818359375e-05\n",
      "2.0 1.0000109672546387 2.2411346435546875e-05\n",
      "2.0 1.0000107288360596 2.193450927734375e-05\n",
      "2.0 1.0000104904174805 2.1457672119140625e-05\n",
      "2.0 1.0000102519989014 2.09808349609375e-05\n",
      "2.0 1.0000100135803223 2.0503997802734375e-05\n",
      "2.0 1.0000097751617432 2.002716064453125e-05\n",
      "2.0 1.000009536743164 1.9550323486328125e-05\n",
      "2.0 1.000009298324585 1.9073486328125e-05\n",
      "2.0 1.0000090599060059 1.8596649169921875e-05\n",
      "2.0 1.0000088214874268 1.811981201171875e-05\n",
      "2.0 1.0000087022781372 1.7642974853515625e-05\n",
      "2.0 1.0000085830688477 1.7404556274414062e-05\n",
      "2.0 1.000008463859558 1.71661376953125e-05\n",
      "2.0 1.0000083446502686 1.6927719116210938e-05\n",
      "2.0 1.000008225440979 1.6689300537109375e-05\n",
      "2.0 1.0000081062316895 1.6450881958007812e-05\n",
      "2.0 1.0000079870224 1.621246337890625e-05\n",
      "2.0 1.0000078678131104 1.5974044799804688e-05\n",
      "2.0 1.0000077486038208 1.5735626220703125e-05\n",
      "2.0 1.0000076293945312 1.5497207641601562e-05\n",
      "2.0 1.0000075101852417 1.52587890625e-05\n",
      "2.0 1.0000073909759521 1.5020370483398438e-05\n",
      "2.0 1.0000072717666626 1.4781951904296875e-05\n",
      "2.0 1.000007152557373 1.4543533325195312e-05\n",
      "2.0 1.0000070333480835 1.430511474609375e-05\n",
      "2.0 1.000006914138794 1.4066696166992188e-05\n",
      "2.0 1.0000067949295044 1.3828277587890625e-05\n",
      "2.0 1.0000066757202148 1.3589859008789062e-05\n",
      "2.0 1.0000065565109253 1.33514404296875e-05\n",
      "2.0 1.0000064373016357 1.3113021850585938e-05\n",
      "2.0 1.0000063180923462 1.2874603271484375e-05\n",
      "2.0 1.0000061988830566 1.2636184692382812e-05\n",
      "2.0 1.000006079673767 1.239776611328125e-05\n",
      "2.0 1.0000059604644775 1.2159347534179688e-05\n",
      "2.0 1.000005841255188 1.1920928955078125e-05\n",
      "2.0 1.0000057220458984 1.1682510375976562e-05\n",
      "2.0 1.0000056028366089 1.1444091796875e-05\n",
      "2.0 1.0000054836273193 1.1205673217773438e-05\n",
      "2.0 1.0000053644180298 1.0967254638671875e-05\n",
      "2.0 1.0000052452087402 1.0728836059570312e-05\n",
      "2.0 1.0000051259994507 1.049041748046875e-05\n",
      "2.0 1.0000050067901611 1.0251998901367188e-05\n",
      "2.0 1.0000048875808716 1.0013580322265625e-05\n",
      "2.0 1.000004768371582 9.775161743164062e-06\n",
      "2.0 1.0000046491622925 9.5367431640625e-06\n",
      "2.0 1.000004529953003 9.298324584960938e-06\n",
      "2.0 1.0000044107437134 9.059906005859375e-06\n",
      "2.0 1.0000042915344238 8.821487426757812e-06\n",
      "2.0 1.0000041723251343 8.58306884765625e-06\n",
      "2.0 1.0000040531158447 8.344650268554688e-06\n",
      "2.0 1.0000039339065552 8.106231689453125e-06\n",
      "2.0 1.0000038146972656 7.867813110351562e-06\n",
      "2.0 1.000003695487976 7.62939453125e-06\n",
      "2.0 1.0000035762786865 7.3909759521484375e-06\n",
      "2.0 1.000003457069397 7.152557373046875e-06\n",
      "2.0 1.0000033378601074 6.9141387939453125e-06\n",
      "2.0 1.0000032186508179 6.67572021484375e-06\n",
      "2.0 1.0000030994415283 6.4373016357421875e-06\n",
      "2.0 1.0000029802322388 6.198883056640625e-06\n",
      "2.0 1.0000028610229492 5.9604644775390625e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "2.0 1.0000028610229492 5.7220458984375e-06\n",
      "y is minimum at x = 1\n",
      "x =  1.0000028610229492\n",
      "y =  2.0\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum of y\n",
    "for _ in range(1000):\n",
    "  y = (x - 1).pow(2) + 2\n",
    "  y.backward()\n",
    "\n",
    "  x.data = x.data - 0.01 * x.grad.data\n",
    "  print(y.item(), x.item(), x.grad.data.item())\n",
    "  x.grad.data.zero_()\n",
    "\n",
    "print('y is minimum at x = 1')\n",
    "print('x = ', x.item())\n",
    "print('y = ', y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cu1gu5TJsYZ-",
    "outputId": "6f7e47be-67fe-4f66-cd29-4e8702b74a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# y = 2 * x + 3 * z\n",
    "x = torch.tensor(10.0,requires_grad=True)\n",
    "z = torch.tensor(20.1,requires_grad=True)\n",
    "y = 2*x + 3*z\n",
    "y.backward()\n",
    "\n",
    "print(x.grad.data,z.grad.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzfnq7qbnH4t"
   },
   "source": [
    "### Modules (layers)\n",
    "\n",
    "`Module` is a basic component of a computation graph in PyTorch, including all kinds of layers (https://pytorch.org/docs/stable/nn.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NAp_UpbMnHcB",
    "outputId": "d66fb2ec-efd9-47cf-f7ce-63d7c1f4130c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After linear torch.Size([10, 30])\n",
      "Before ReLU: tensor([ 0.3038,  0.5615, -0.4189, -0.0026,  0.0013], grad_fn=<SliceBackward>)\n",
      "Chaining modules: tensor([0.3038, 0.5615, 0.0000, 0.0000, 0.0013], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_dim = 20\n",
    "output_dim = 30\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input = torch.randn(10, input_dim)\n",
    "\n",
    "# Linear transform (fully connected layer)\n",
    "linear_module = nn.Linear(input_dim, output_dim, bias = True)\n",
    "output = linear_module(input)\n",
    "\n",
    "print('After linear', output.shape)\n",
    "\n",
    "# ReLU\n",
    "relu_module = nn.ReLU()\n",
    "relu_output = relu_module(output)\n",
    "\n",
    "print('Before ReLU:', output[0, :5])\n",
    "print('Chaining modules:', relu_output[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W71Xl5MOj73H"
   },
   "source": [
    "### Sequential (sequence of modules)\n",
    "\n",
    "`nn.Sequential(module1, module2, ...)` can chain a sequence of modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1syBPOxYkGLu",
    "outputId": "c0585fe6-681b-43ba-d666-a1d994feacce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential: tensor([0.3038, 0.5615, 0.0000, 0.0000, 0.0013], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Combine modules\n",
    "sequential_module = nn.Sequential(linear_module, relu_module)\n",
    "\n",
    "sequential_output = sequential_module(input)\n",
    "# print(sequential_output.shape)\n",
    "\n",
    "print('Sequential:', sequential_output[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnWq2sCIpLJY"
   },
   "source": [
    "### Models\n",
    "\n",
    "To build complex modules and reuse them, you can define your own Module class, like `Model1`, `Model2`, and `Model3`.\n",
    "Modules (layers) defined in a module will be automatically added to the computation graph.\n",
    "\n",
    "Your custom module should inherit from `nn.Module`. `super().__init__()` should be added in your `__init__()` method.\n",
    "You also need to implement your own `forward()` function which describes the forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuYvIGJgDH7r"
   },
   "source": [
    "Define layers using member variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Cory4c0ypO5v",
    "outputId": "3f2cb9ae-6317-4eee-e2d5-071dce479c7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1(\n",
      "  (linear_module): Linear(in_features=20, out_features=30, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Model 1 output: tensor([0.0000, 0.4561, 0.0000, 0.0000, 0.0000], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Model1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() # must be added before define you module\n",
    "    \n",
    "    # Define layers as member variables\n",
    "    self.linear_module = nn.Linear(input_dim, output_dim, bias = True)\n",
    "    self.relu = nn.ReLU()\n",
    "    pass\n",
    "    \n",
    "  def forward(self, input):\n",
    "    # Define forward pass (input -> linear module -> relu -> output)\n",
    "    output1 = self.linear_module(input)\n",
    "    output2 = self.relu(output1)\n",
    "    return output2\n",
    "\n",
    "  \n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Make a model\n",
    "model1 = Model1()\n",
    "\n",
    "# Run forward pass. model1(input) == model1.forward(input)\n",
    "model1_output = model1(input)\n",
    "\n",
    "print(model1)\n",
    "print('Model 1 output:', model1_output[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AiwedfslDPpk"
   },
   "source": [
    "Define layers using `nn.Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "n8321V5bjWM9",
    "outputId": "9e6fba58-0f4d-430b-d18f-a0ad33d41b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model2(\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "Model 2 output: tensor([0.0000, 0.4561, 0.0000, 0.0000, 0.0000], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Model2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    # Define layers as a sequential\n",
    "    linear = nn.Linear(input_dim, output_dim, bias = True)\n",
    "    relu = nn.ReLU()\n",
    "    \n",
    "    self.seq = nn.Sequential(linear, relu)\n",
    "    pass\n",
    "    \n",
    "  def forward(self, input):\n",
    "    output = self.seq(input)\n",
    "    return output\n",
    "  \n",
    "  \n",
    "torch.manual_seed(123)\n",
    "model2 = Model2()\n",
    "model2_output = model2(input)\n",
    "\n",
    "print(model2)\n",
    "print('Model 2 output:', model2_output[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diqlp6CUDTF0"
   },
   "source": [
    "Define layers using `nn.ModuleList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "2r77JGC1jZKs",
    "outputId": "cad0c8ea-d208-4b31-cdad-6f634c8042bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model3(\n",
      "  (module_list): ModuleList(\n",
      "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "Model 3 output: tensor([0.0000, 0.4561, 0.0000, 0.0000, 0.0000], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Model3(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    # Define layers as a module list\n",
    "    linear = nn.Linear(input_dim, output_dim, bias = True)\n",
    "    relu = nn.ReLU()\n",
    "    \n",
    "    self.module_list = nn.ModuleList([linear, relu])\n",
    "    pass\n",
    "    \n",
    "  def forward(self, input):\n",
    "    output1 = self.module_list[0](input)\n",
    "    output2 = self.module_list[1](output1)\n",
    "    return output2\n",
    "  \n",
    "  \n",
    "torch.manual_seed(123)\n",
    "model3 = Model3()\n",
    "model3_output = model3(input)\n",
    "\n",
    "print(model3)\n",
    "print('Model 3 output:', model3_output[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOYTp4d6lh2h"
   },
   "source": [
    "### Simple MLP module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "l9hI4u88lbV2",
    "outputId": "7100af6f-70b4-4efc-a650-b780685a10cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=30, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, hidden_dims=[]):\n",
    "    super().__init__()\n",
    "    \n",
    "    # Define layers\n",
    "    fc = []\n",
    "    previous_dim = input_dim\n",
    "    for dim in hidden_dims:\n",
    "      fc.append(\n",
    "          nn.Linear(previous_dim, dim)\n",
    "      )\n",
    "      fc.append(\n",
    "          nn.ReLU()\n",
    "      )\n",
    "      previous_dim = dim\n",
    "    \n",
    "    fc.append(\n",
    "        nn.Linear(previous_dim, output_dim)\n",
    "    )\n",
    "    \n",
    "    # Convert a list of layers to a sequential module\n",
    "    #######like unzip tuple in python\n",
    "    self.fc = nn.Sequential(*fc)\n",
    "  \n",
    "  def forward(self, observation):\n",
    "    return self.fc(observation)\n",
    "  \n",
    "  \n",
    "mlp = MLP(100, 20, [30, 30])\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFxguuPOlkso"
   },
   "source": [
    "### Be careful!\n",
    "\n",
    "If layers are not referenced by member variables and not added to `Sequential`, `ModuleList`, and `ModuleDict`, your module cannot update those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "POEGEaoZlnT9",
    "outputId": "85b64eb9-32cc-49d8-bcda-7f0a0a3ba934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_wrong()\n"
     ]
    }
   ],
   "source": [
    "# Wrong MLP module\n",
    "class MLP_wrong(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, hidden_dims=[]):\n",
    "    super().__init__()\n",
    "    \n",
    "    fc = []\n",
    "    previous_dim = input_dim\n",
    "    for dim in hidden_dims:\n",
    "      fc.append(\n",
    "          nn.Linear(previous_dim, dim)\n",
    "      )\n",
    "      fc.append(\n",
    "          nn.ReLU()\n",
    "      )\n",
    "      previous_dim = dim\n",
    "    \n",
    "    fc.append(\n",
    "        nn.Linear(previous_dim, output_dim)\n",
    "    )\n",
    "    \n",
    "    self.fc = fc # MLP module does not know about these layers\n",
    "    \n",
    "  def forward(self, observation):\n",
    "    output = observation\n",
    "    for layer in self.fc:\n",
    "      output = self.fc(output)\n",
    "    return output\n",
    "\n",
    "  \n",
    "mlp_wrong = MLP_wrong(100, 20, [30, 30])\n",
    "print(mlp_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0T_QNdipHq9"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "15ZtNkQKhQiR",
    "outputId": "3eb35782-0d26-4b98-e932-0f3e66831249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2141, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1981, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1952, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1925, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1898, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1872, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Optimizers\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=1e-3)\n",
    "\n",
    "true_output = torch.rand(output_dim)\n",
    "rnd_input = torch.rand(input_dim)\n",
    "\n",
    "for _ in range(10):\n",
    "  # Predicted output\n",
    "  predicted_output = model2(rnd_input)\n",
    "  \n",
    "  # Compute loss\n",
    "  loss = loss_fn(predicted_output, true_output)\n",
    "  print(loss)\n",
    "\n",
    "  # Update model\n",
    "  optimizer.zero_grad() # Zero out previous gradients\n",
    "  loss.backward()  # Compute new gradients\n",
    "  optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdhZ3sZgiPUI"
   },
   "source": [
    "### GPU support\n",
    "\n",
    "You need to define your tensors in GPU.\n",
    "\n",
    "It can be done by \n",
    "\n",
    "`x = torch.tensor(data, device=torch.device(\"cuda\"))` \n",
    "\n",
    "or \n",
    "\n",
    "`x = torch.tensor(data).to(torch.device(\"cuda\"))`.\n",
    "\n",
    "or \n",
    "\n",
    "`x = torch.tensor(data).cuda()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmnclDosiR9Y"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") \n",
    "# For gpu\n",
    "# device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDV-ghZJRm4T"
   },
   "source": [
    "## OpenAI gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFLNQXMWP0mf"
   },
   "source": [
    "### Installation\n",
    "\n",
    "You can simply install OpenAI gym by executing `pip install gym`.\n",
    "\n",
    "Here, we are using a virtual display to render videos in a headless server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EnEOmhbeuL42",
    "outputId": "c512929c-8942-4c2b-f4e8-a50cf7e745ed"
   },
   "outputs": [
    {
     "ename": "EasyProcessCheckInstalledError",
     "evalue": "cmd=['Xvfb', '-help']\nOSError=[Errno 2] No such file or directory: 'Xvfb': 'Xvfb'\nProgram install error! ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                           \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                                           \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m                                           )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1521\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Xvfb': 'Xvfb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEasyProcessError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mcheck_installed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moserror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moserror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEasyProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEasyProcessError\u001b[0m: start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[Errno 2] No such file or directory: 'Xvfb': 'Xvfb' return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEasyProcessCheckInstalledError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3a2b86eabddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyvirtualdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pyvirtualdisplay/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, check_startup, randomizer, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'xvfb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         self._obj = self.display_class(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mcolor_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pyvirtualdisplay/display.py\u001b[0m in \u001b[0;36mdisplay_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# TODO: check only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_installed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pyvirtualdisplay/xvfb.py\u001b[0m in \u001b[0;36mcheck_installed\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_installed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         EasyProcess([PROGRAM, '-help'], url=URL,\n\u001b[0;32m---> 40\u001b[0;31m                     ubuntu_package=PACKAGE).check_installed()\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mcheck_installed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEasyProcessCheckInstalledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEasyProcessCheckInstalledError\u001b[0m: cmd=['Xvfb', '-help']\nOSError=[Errno 2] No such file or directory: 'Xvfb': 'Xvfb'\nProgram install error! "
     ]
    }
   ],
   "source": [
    "# Render OpenAI gym: code from https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t\n",
    "\n",
    "# !pip install gym > /dev/null 2>&1\n",
    "# !apt-get install python-opengl -y > /dev/null 2>&1\n",
    "# !apt install xvfb -y > /dev/null 2>&1\n",
    "# !pip install gym[atari] > /dev/null 2>&1\n",
    "# !pip install pyvirtualdisplay > /dev/null 2>&1\n",
    "# !pip install pyglet==1.3.2 > /dev/null 2>&1\n",
    "\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "\n",
    "# This code creates a virtual display to draw game images on. \n",
    "# If you are running locally, just ignore it\n",
    "# import os\n",
    "# if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "#     !bash ../xvfb start\n",
    "#     %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TInxwg9Wyex6"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from collections import defaultdict\n",
    "\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "\n",
    "def show_video():\n",
    "  mp4list = glob.glob('video/*.mp4')\n",
    "  if len(mp4list) > 0:\n",
    "    mp4 = mp4list[0]\n",
    "    video = io.open(mp4, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "  else: \n",
    "    print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "  env = Monitor(env, './video', force=True)\n",
    "  return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cx1kmBfQVbo"
   },
   "source": [
    "### Make an environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "jtV4hhHdy7Bt",
    "outputId": "f8045ddb-8da6-4f30-fc7d-f132f35a9aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(4,)\n",
      "Action space: Discrete(2)\n",
      "Initial observation: [ 0.01 -0.03 -0.03  0.  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13ee38f10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make an environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Observation space\n",
    "print('Observation space:', env.observation_space)\n",
    "\n",
    "# Action space\n",
    "print('Action space:', env.action_space)\n",
    "\n",
    "# Reset an episode and get an initial state\n",
    "observation = env.reset()\n",
    "\n",
    "print('Initial observation:', observation)\n",
    "\n",
    "# Render an image\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXqAaAx3pyyx"
   },
   "source": [
    "### Take a step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "HR2CQcCNQ1Fc",
    "outputId": "a6b0640d-4e94-4e69-e470-78f7c9f9efa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random action 0\n",
      "Observation [ 0.   -0.03  0.03  0.02]\n",
      "Next observation [ 0.   -0.23  0.03  0.32]\n",
      "Reward 1.0\n",
      "Done False\n",
      "Info {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b6e8bd5c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEBCAYAAACUmXXrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFRBJREFUeJzt3X9M0/nhx/EXxRTn7aAWgxa8SDSH\n6SSZG038yy2rZrAMkcuyQRrdkjvvLiFHnAanmwoLahxozLYcF1y8LFlC5B+mCOdAL8RsM5nRMZYx\nL54h4tjodIBM/AEL7fv7x32vObezLT96pbyfj8Tcte9P7ftte08/9+mnH9KMMUYAACs4kj0BAMBn\nh+gDgEWIPgBYhOgDgEWIPgBYhOgDgEWIPgBYhOgDgEUSGv07d+6ooqJCxcXFqqio0ODgYCKfDgAQ\nQ0KjX1dXp0AgoO7ubgUCAdXW1iby6QAAMSQs+qOjo7p586ZKS0slSaWlpbp586bGxsYS9ZQAgBgS\nFv1gMKiVK1cqPT1dkpSenq6cnBwFg8FEPSUAIAY+yAUAiyQs+h6PR/fu3VMoFJIkhUIh3b9/Xx6P\nJ1FPCQCIIWHRz87OltfrVWdnpySps7NTXq9Xbrc7UU8JAIghLZHX0x8YGNCBAwf08OFDZWZmqqGh\nQWvXrk3U0wEAYkho9AEACwsf5AKARYg+AFiE6AOARYg+AFiE6AOARYg+AFiE6AOARYg+AFiE6AOA\nRYg+AFiE6AOARYg+AFiE6AOARYg+AFiE6AOARYg+AFiE6AOARYg+AFiE6AOARZbM9Tfw+/1yOp3K\nyMiQJNXU1Gjz5s3q6+tTbW2tpqamlJeXpxMnTig7O3vOEwYAzN6cfzC63+9Xc3OzCgoKIveFw2EV\nFxfr+PHj8vl8eueddzQ0NKTjx4/PecIAgNlLyOGd/v5+ZWRkyOfzSZIqKyvV1dWViKcCAMzAnA/v\nSB8d0jHGqKioSHv37lUwGFRubm5k3O12KxwOa3x8XC6Xaz6eEgAwC3Pe029padGFCxfU1tYmY4zq\n6+vnY14AgASYc/Q9Ho8kyel0KhAIqLe3Vx6PR8PDw5FtxsbG5HA42MsHgCSbU/SfPHmiiYkJSZIx\nRhcvXpTX61VhYaEmJyd148YNSVJra6tKSkrmPlsAwJzM6eydoaEhVVdXKxQKKRwOa926dTp06JBy\ncnLU29ururq6Z07ZXLFixXzOHQAwQ3M+ZRMAkDr4Ri4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BF\niD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFYka/\noaFBfr9f69ev14cffhi5/86dO6qoqFBxcbEqKio0ODgY1xgAIHliRn/Lli1qaWlRXl7eM/fX1dUp\nEAiou7tbgUBAtbW1cY0BAJInZvR9Pp88Hs8z942OjurmzZsqLS2VJJWWlurmzZsaGxuLOgYASK4l\ns3lQMBjUypUrlZ6eLklKT09XTk6OgsGgjDHPHXO73fM3cwDAjPFBLgBYZFZ7+h6PR/fu3VMoFFJ6\nerpCoZDu378vj8cjY8xzxwAAyTWrPf3s7Gx5vV51dnZKkjo7O+X1euV2u6OOAQCSK80YY6JtcPTo\nUV26dEkjIyNavny5XC6X3nvvPQ0MDOjAgQN6+PChMjMz1dDQoLVr10pS1DEAQPLEjD4AYPHgg1wA\nsAjRBwCLEH0AsAjRBwCLEH0AsAjRBwCLEH0AsAjRBwCLEH0AsAjRBwCLEH0AsAjRBwCLEH0AsAjR\nBwCLEH0AsAjRBwCLEH0AsAjRBwCLLIlno4aGBnV3d+sf//iHOjo6VFBQIEny+/1yOp3KyMiQJNXU\n1Gjz5s2SpL6+PtXW1mpqakp5eXk6ceKEsrOzE7QMAEA84trT37Jli1paWpSXl/c/Yz//+c/V3t6u\n9vb2SPDD4bD27dun2tpadXd3y+fz6eTJk/M7cwDAjMUVfZ/PJ4/HE/dv2t/fr4yMDPl8PklSZWWl\nurq6ZjdDAMC8ievwTjQ1NTUyxqioqEh79+5VZmamgsGgcnNzI9u43W6Fw2GNj4/L5XLN9SkBALM0\npw9yW1padOHCBbW1tckYo/r6+vmaFwAgAeYU/Y8P+TidTgUCAfX29kbuHx4ejmw3NjYmh8PBXj4A\nJNmso//kyRNNTExIkowxunjxorxerySpsLBQk5OTunHjhiSptbVVJSUl8zBdAMBcpBljTKyNjh49\nqkuXLmlkZETLly+Xy+VSc3OzqqurFQqFFA6HtW7dOh06dEg5OTmSpN7eXtXV1T1zyuaKFSsSviAA\nwPPFFX0AwOLAN3IBwCJEHwAsQvQBwCJEHwAsQvQBwCJEHwAsMudr7wA2+OMv3nzmdtEbp5M0E2Bu\n2NMHAIsQfQCwCNEHAIsQfQCwCNEHAIsQfSCK/z5rB0h1RB8ALEL0AcAiRB8ALEL0AcAiRB8ALBIz\n+g8ePNDrr7+u4uJibdu2TW+99ZbGxsYkSX19fSorK1NxcbFeffVVjY6ORh4XbQwAkBwxo5+WlqZd\nu3apu7tbHR0deumll3Ty5EmFw2Ht27dPtbW16u7uls/n08mTJyUp6hgAIHliRt/lcmnTpk2R2xs3\nbtTw8LD6+/uVkZEhn88nSaqsrFRXV5ckRR0DACTPjI7ph8NhnT17Vn6/X8FgULm5uZExt9utcDis\n8fHxqGMAgOSZ0fX0jxw5omXLlmnHjh26fPlyouYELBgfXzef6+djsYg7+g0NDbp7966am5vlcDjk\n8Xg0PDwcGR8bG5PD4ZDL5Yo6BqSSP/7iTRW9cZofooJFI67DO6dOnVJ/f7+amprkdDolSYWFhZqc\nnNSNGzckSa2trSopKYk5BgBInph7+rdv39bp06eVn5+vyspKSdLq1avV1NSkxsZG1dXVaWpqSnl5\neTpx4oQkyeFwPHcMAJA8MaP/8ssv69atW5869uUvf1kdHR0zHgMAJAffyAUAixB9ALAI0QcAixB9\nYIY4XROpjOgDgEWIPgBYhOgDgEWIPgBYhOgDgEWIPgBYhOgDgEWIPgBYhOgDgEWIPgBYhOgDgEWI\nPgBYhOgDgEWIPgBYJOaPS3zw4IF+8IMf6G9/+5ucTqfWrFmj+vp6ud1urV+/XgUFBXI4Pvq7o7Gx\nUevXr5ck9fT0qLGxUaFQSBs2bNDx48f1uc99LrGrAQBEFXNPPy0tTbt27VJ3d7c6Ojr00ksv6eTJ\nk5Hx1tZWtbe3q729PRL8x48f6/Dhw2pubtbly5f1wgsv6N13303cKgAAcYkZfZfLpU2bNkVub9y4\nUcPDw1Ef89vf/laFhYXKz8+XJFVWVuo3v/nN3GYKAJizmId3PikcDuvs2bPy+/2R+3bu3KlQKKSv\nfOUrqq6ultPpVDAYVG5ubmSb3NxcBYPB+Zs18Bn44y/eTPYUgHk3o+gfOXJEy5Yt044dOyRJV65c\nkcfj0aNHj7Rv3z41NTVpz549CZko8Fn75I9F5EckYrGIO/oNDQ26e/eumpubIx/cejweSdLnP/95\nffvb39Yvf/nLyP3Xrl2LPHZ4eDiyLZAqPt7TL3rj9DN7/fwFgFQW1ymbp06dUn9/v5qamuR0OiVJ\n//73vzU5OSlJmp6eVnd3t7xeryRp8+bN+stf/qLBwUFJH33Y+41vfCMB0wcAzETMPf3bt2/r9OnT\nys/PV2VlpSRp9erV2rVrl2pra5WWlqbp6Wl96Utf0u7duyV9tOdfX1+vN998U+FwWF6vVwcPHkzs\nSgAAMcWM/ssvv6xbt2596lhHR8dzH7d161Zt3bp19jMDAMw7vpELABYh+gBgEaIPABYh+gBgEaIP\nABYh+gBgEaIPABYh+gBgEaIPABYh+gBgEaIPABYh+sAMcFllpDqiDwAWIfqwSlpaWty/EvF4INmI\nPgBYhOgDUXQG33jmn0CqI/rAc/x36Ak/FgOiDwAWIfoAYJG4ol9VVaWysjKVl5crEAjogw8+kCTd\nuXNHFRUVKi4uVkVFhQYHByOPiTYGpIJSzy+i3gZSUZoxxsTaaGJiQi+++KIk6f3331dTU5POnTun\n7373u/rWt76l7du3q729XW1tbfrVr34lSVHHgGSZzamUxphZPw5YcMwMnTt3zrzyyitmZGTEFBUV\nmenpaWOMMdPT06aoqMiMjo5GHZuJNWvWGEmL6tf//yW7KH8t1rWxrtT7tRjXtmbNmpnm+lMtUZwO\nHjyoq1evyhijM2fOKBgMauXKlUpPT5ckpaenKycnR8FgUMaY54653e54n3LRHhIyi3gPcLGujXWl\nnsW8trmIO/rHjh2TJJ0/f16NjY3avXt3wiYFJAqHd2C7GZ+9U15ermvXrmnVqlW6d++eQqGQJCkU\nCun+/fvyeDzyeDzPHQMAJE/M6D9+/FjBYDByu6enR1lZWcrOzpbX61VnZ6ckqbOzU16vV263O+oY\nACB5Yp69MzIyoqqqKj19+lQOh0NZWVnav3+/NmzYoIGBAR04cEAPHz5UZmamGhoatHbtWkmKOgYk\nC4d3YLu4TtkEFguiD9vxjVwAsAjRBwCLcHgHACzCnj4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BF\niD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWGRJPBtVVVXp73//uxwOh5Yt\nW6bDhw/L6/XK7/fL6XQqIyNDklRTU6PNmzdLkvr6+lRbW6upqSnl5eXpxIkTys7OTtxKAAAxxfVD\nVCYmJvTiiy9Kkt5//301NTXp3Llz8vv9am5uVkFBwTPbh8NhFRcX6/jx4/L5fHrnnXc0NDSk48eP\nJ2YVAIC4xHV45+PgS9KjR49i/pDo/v5+ZWRkyOfzSZIqKyvV1dU1h2kCAOZDXId3JOngwYO6evWq\njDE6c+ZM5P6amhoZY1RUVKS9e/cqMzNTwWBQubm5kW3cbrfC4bDGx8flcrnmdwUAgLjF/UHusWPH\ndOXKFe3Zs0eNjY2SpJaWFl24cEFtbW0yxqi+vj5hEwUAzN2Mz94pLy/XtWvX9ODBA3k8HkmS0+lU\nIBBQb2+vJMnj8Wh4eDjymLGxMTkcDvbyASDJYkb/8ePHCgaDkds9PT3KyspSRkaGJiYmJEnGGF28\neFFer1eSVFhYqMnJSd24cUOS1NraqpKSkkTMHwAwAzHP3hkZGVFVVZWePn0qh8OhrKws7d+/X5mZ\nmaqurlYoFFI4HNa6det06NAh5eTkSJJ6e3tVV1f3zCmbK1as+EwWBQD4dHGdsgkAWBz4Ri4AWITo\nA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BFiD4AWIToA4BF\niD4AWIToA4BFiD4AWIToA4BFZhT9t99+W+vXr9eHH34oSerr61NZWZmKi4v16quvanR0NLJttDEA\nQHLEHf2//vWv6uvrU15eniQpHA5r3759qq2tVXd3t3w+n06ePBlzDACQPHFF/z//+Y/q6+v14x//\nOHJff3+/MjIy5PP5JEmVlZXq6uqKOQYASJ64ov+zn/1MZWVlWr16deS+YDCo3NzcyG23261wOKzx\n8fGoYwCA5IkZ/T/96U/q7+9XIBD4LOYDAEigJbE2uH79ugYGBrRlyxZJ0j//+U+99tpr2rlzp4aH\nhyPbjY2NyeFwyOVyyePxPHcMAJA8Mff033jjDf3+979XT0+Penp6tGrVKr377rvatWuXJicndePG\nDUlSa2urSkpKJEmFhYXPHQMAJE/MPf3ncTgcamxsVF1dnaamppSXl6cTJ07EHAMAJE+aMcYkexIA\ngM8G38gFAIsQfQCwCNEHAIsQfQCwyIKL/p07d1RRUaHi4mJVVFRocHAw2VOKW0NDg/x+/zMXpZOi\nrykV1vvgwQO9/vrrKi4u1rZt2/TWW29pbGxMUupfdK+qqkplZWUqLy9XIBDQBx98ICn1X7OPLcaL\nJPr9fpWUlGj79u3avn27fve730lK/bVNTU2prq5OX//617Vt2zYdPnxYUgLei2aB2blzpzl//rwx\nxpjz58+bnTt3JnlG8bt+/boZHh42X/va18ytW7ci90dbUyqs98GDB+YPf/hD5PZPfvIT88Mf/tCE\nQiGzdetWc/36dWOMMU1NTebAgQPGGBN1bCF5+PBh5N8vX75sysvLjTGp/5oZY0x/f7957bXXIu/H\nxfB6GWP+578vY6LPP1XWduTIEXPs2DETDoeNMcb861//MsbM/3txQUV/ZGTEFBUVmenpaWOMMdPT\n06aoqMiMjo4meWYz88k3ZbQ1pep6u7q6zPe+9z3z5z//2Xzzm9+M3D86Omo2btxojDFRxxaqc+fO\nmVdeeWVRvGZTU1PmO9/5jhkaGoq8HxfL6/Vp0U/1tT169MgUFRWZR48ePXN/It6Ls/5yViIEg0Gt\nXLlS6enpkqT09HTl5OQoGAzK7XYneXazE21NxpiUW284HNbZs2fl9/tnfdG9hXY5joMHD+rq1asy\nxujMmTOL4jWbz4skLrTXS5JqampkjFFRUZH27t2b8msbGhqSy+XS22+/rWvXrumFF17Q7t27tXTp\n0nl/Ly64Y/pY2I4cOaJly5Zpx44dyZ7KvDl27JiuXLmiPXv2qLGxMdnTmbPFfpHElpYWXbhwQW1t\nbTLGqL6+PtlTmrNQKKShoSF94Qtf0K9//WvV1NSourpaT548mffnWlDR93g8unfvnkKhkKSP/iDu\n378vj8eT5JnNXrQ1pdp6GxoadPfuXf30pz+Vw+GIemG9VLzoXnl5ua5du6ZVq1al9Gv2yYsk+v3+\nyEUS7969uyher4//rJ1OpwKBgHp7e1P+vejxeLRkyRKVlpZKkr74xS9q+fLlWrp06by/FxdU9LOz\ns+X1etXZ2SlJ6uzslNfrXVD/2zxT0daUSus9deqU+vv71dTUJKfTKSn6hfVS4aJ7jx8/VjAYjNzu\n6elRVlZWyr9mi/kiiU+ePNHExIQkyRijixcvyuv1pvx70e12a9OmTbp69aqkj87KGR0dVX5+/ry/\nFxfctXcGBgZ04MABPXz4UJmZmWpoaNDatWuTPa24HD16VJcuXdLIyIiWL18ul8ul9957L+qaUmG9\nt2/fVmlpqfLz87V06VJJ0urVq9XU1KTe3t7/ubDeihUrJCnq2EIwMjKiqqoqPX36VA6HQ1lZWdq/\nf782bNiQ8q/ZJ/n9fjU3N6ugoCClXy/po2Pf1dXVCoVCCofDWrdunQ4dOqScnJxFsbYf/ehHGh8f\n15IlS/T9739fX/3qV+f9vbjgog8ASJwFdXgHAJBYRB8ALEL0AcAiRB8ALEL0AcAiRB8ALEL0AcAi\nRB8ALPJ/4fG+0YAw5DUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample one random action\n",
    "random_action = env.action_space.sample()\n",
    "print('Random action', random_action)\n",
    "\n",
    "# Take a step\n",
    "observation_next, reward, done, info = env.step(random_action)\n",
    "\n",
    "print('Observation', observation)\n",
    "print('Next observation', observation_next)\n",
    "print('Reward', reward)\n",
    "print('Done', done)\n",
    "print('Info', info)\n",
    "\n",
    "# Render an image\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xrrmm_yAqF-4"
   },
   "source": [
    "### Run one episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "colab_type": "code",
    "id": "PqAoppv-RGL_",
    "outputId": "c27d5f8d-635b-4e85-ba0a-e99152aa9668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 10.0\n",
      "Total length: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" autoplay \n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAACUhtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAB9WWIhAAv//72rvzLK0cLlS4dWXuzUfLoSXL9iDB9aAAAAwAAAwAAJuKiZ0WFMeJsgAAALmAIWElDyDzETFWKvTAZoCvgxX+ABFNfe2BY5KHnsdIRFcc3mroscfOLJaWfE65+/j+bJ6DkoYU1hzf+qN4FZBsOqNpgbC0e1qzFgwzGX5ontp7u+F/8s/2P3GmG9UQhXvB27vbbVRiC6ghQPnU2KsNjkgAeLWdfddji/ZwWYeypBPr9hZCvH7kLegECTeeRs2IoUWQzcaw87PGkxnwn1U4DjxVAL72cXBINvxVDG/z3n5DaagjidXr4Q47O7/wZdl52CTGdyiAEu3yYqqMy03zVoVqqRhzyNhk3o/K5wDqutVYeMr+tpCZ3QPMjNv/Ey+8CsDPYZZDQUmruGCQGTzbhGnT1Z1T2olRtBisLRDlGP22rl0oadItZK5v9bmzEPh4L/q8oFe8yt1No6DRkcXrURMnxIynFhpB8AOvRNCYjgQOsPiyxLQ3THFBFhd+JF+crjBN4nDb0nWeQnAp14p6D5THV+ThGUUr3QFtStOlyrtJ4ICpSqQsYjOXc7ItwAFOfyCcgBZFI0Z8q+vcIqHNcS2Ln90hZNUoPsMI73XxHxZMiBYQi8eQFePXKiZrt3R4GWLH3IEA9AAADAAADAABswQAAAMZBmiRsQr/+OEAAAQ0amqABx2rf4bzvFoJSBXUVoZhg6xWIaTDy+EVFU5UKPisESEqLf1thj8utN4+W/tbQynfVvPRObDpV/9Q9fXcDQVv9J2D+8O4ZYeniN2KJIk38pRG3PUp/6g/wnryu/CcrriKqW2hyHv70oSigka8VAFSven9CR+lPusS3DbA8zljx2oGcaxbfRcc4Kad5VOZ1fS2w6C0oz6BMHkDG+CELG+AAAAMC752zvBhZ8c8X7Ku4BrBRW/N1eYAAAABNQZ5CeIR/AAAWrZ+L7A1AbmtHu2d+wfavH/lSaEBXOZmKaAC52cCfDXaJ5o2bedBZ/tFssuCCTH4oxRBNMRF4AAADACXPj8DDaDwgN6EAAAA4AZ5hdEf/AAAFHPSG17h3TBcCstyXOJ3Pw7N0n/Kw1xg+jCl/qdWAAAADAAADA5/G18yM+GdIlYAAAABGAZ5jakf/AAAjsixmiew1GH19/e2UYXp4d/dF8vlkgSu3cmWu8gBLVtt/4WB8Wew9/QoSo/B/ami7AAADAAehUq+m6MsB/wAAAKNBmmhJqEFomUwIT//98QAAAwKw7Y2JpK7+fRynAIIxfmp0QovGMf3PlInB+4MBzzCd0TyqzFE9n/neyD7lAjaifJkXPAV2NPJdrOxVV3E0LG5yprHIvmJ+nUKClmrFyGm/XoP+Avp3SQblW0ePwJ+jOwzpX6tRFN9Byi4nVPC/G16RJIzK/3tqiHzMj5bedeWoc33l40mpTwCWM+QqRRDIPxXBAAAAYEGehkURLCP/AAAXTDO9fhq88gkWbj/h3QzUWj2RwgIhe6TGKSV/iPKK7g5txJ9gFbFd69XjwW631Np8gSwD5kFwAXQEmqTwTBoSHbpnlXffcV263jji2oyxqOPmSTyG4QAAAEYBnqV0R/8AACOEUBwz44i5lJWNMzxwZ0SF192LhR427idqYk4EHEm0MZjBv8lhqO+ePCaFCwwM9R6Id8/sjLedFK/5Sb/BAAAAUgGep2pH/wAAJL7GzVMnpABtzT7K7781r5plMGrNPHvgSg1D/E4+Y/mhIzWiTTJOF5RK5NaXl+tR+MtXvdDHyHfPantK1GHsakLR3fXc2cVtzLwAAACsQZqpSahBbJlMCEf//eEAAAQzXVRjcK8QgAWB/7sHTdjZCZHzx2iX2jU96guooWWg9L2miI16s9bp7VpP2tNjLPnPg56M2ZlmOqVbcXBWxcKaAQvGSBlIohS0ZW50cfBKoksowII7sB0EfUYNhMggn37tJ5T6XkdxishyPLhIPWOGBbMhkogzF3cmyj2Wad+d80l5Fvs5pcEFK4wv1zBglia1yS31FRLrXo9HcAAAAJVBmspJ4QpSZTAj//yEAAAQb1qP9Waco/AyimIvNaPtK1CycLWDsI9l5Mr1QDQ8z1/HEZCmfOdhZszhb75FTYt3EjtWnwCP+xA/1O1Sb3bsjUALGN2z4cUT/7iUSyr0fu2mniwUuH0rh2nr5IuxjMGZ5ADTzHcgDj6DubNMSvM7T+RHRM7s5Du/JgrM4yOEhbRk1r3yEwAAA49tb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAA3AABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAACuXRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAA3AAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACWAAAAZAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAANwAAAIAAAEAAAAAAjFtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAALAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAHcbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAABnHN0YmwAAACYc3RzZAAAAAAAAAABAAAAiGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACWAGQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkAB//4QAZZ2QAH6zZQJgz5eEAAAMAAQAAAwBkDxgxlgEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAAALAAABAAAAABRzdHNzAAAAAAAAAAEAAAABAAAAYGN0dHMAAAAAAAAACgAAAAEAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAIAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAALAAAAAQAAAEBzdHN6AAAAAAAAAAAAAAALAAAEqwAAAMoAAABRAAAAPAAAAEoAAACnAAAAZAAAAEoAAABWAAAAsAAAAJkAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a new environment\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Wrap environment for recording\n",
    "env = wrap_env(env)\n",
    "\n",
    "# Initialize environment\n",
    "observation = env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "# Run until done == True\n",
    "while not done:\n",
    "  # Take a step\n",
    "  observation, reward, done, info = env.step(env.action_space.sample())\n",
    "  \n",
    "  episode_reward += reward\n",
    "  episode_length += 1\n",
    "  \n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "env.close()\n",
    "show_video()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkyoyKkQRr3S"
   },
   "source": [
    "## Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-VXdfNV_y5e"
   },
   "outputs": [],
   "source": [
    "# Dataset for Q-learning\n",
    "# Also called \"experience replay buffer\", \"replay memory\"\n",
    "class Dataset(object):\n",
    "  \n",
    "  def __init__(self, size):\n",
    "    self._size = size\n",
    "    self._transitions = []\n",
    "    self._index = 0\n",
    "    \n",
    "  # Store a transition (s_t, a_t, s_t+1, r_t, done)\n",
    "  def store(self, obs, action, obs_next, reward, done):\n",
    "    transition = {'obs': obs, 'action': action, \n",
    "                  'obs_next': obs_next, 'reward': reward, 'done': done}\n",
    "    \n",
    "    if self._index < self._size:\n",
    "      self._transitions.append(transition)\n",
    "    else:\n",
    "      self._transitions[self._index] = transition\n",
    "      \n",
    "    self._index = (self._index + 1) % self._size\n",
    "\n",
    "  # Sample `batch_size` transitions from the dataset and convert to tensors\n",
    "  def sample(self, batch_size):\n",
    "    indexes = np.random.randint(0, len(self._transitions), batch_size)\n",
    "    batch = {\n",
    "        k: np.stack([self._transitions[i][k] for i in indexes])\n",
    "        for k in ['obs', 'action', 'obs_next', 'reward', 'done']}\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Z537CR_mmW-"
   },
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "  \n",
    "  def __init__(self):\n",
    "    self._history = defaultdict(list)\n",
    "    self._global_history = defaultdict(list)\n",
    "  \n",
    "  def add(self, info):\n",
    "    for k, v in info.items():\n",
    "      self._history[k].append(v)\n",
    "      self._global_history[k].append(v)\n",
    "      \n",
    "  def summary(self):\n",
    "    summary = []\n",
    "    for k, v in self._history.items():\n",
    "      summary.append('{}: {:.2f}'.format(k, np.mean(v)))\n",
    "      \n",
    "    print(', '.join(summary))\n",
    "      \n",
    "    self._history = defaultdict(list)\n",
    "    \n",
    "  def plot(self, key):\n",
    "    n = len(self._global_history[key])\n",
    "    plt.plot(np.arange(n), self._global_history[key])\n",
    "    plt.title(key)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzOw9o0u_zqO"
   },
   "outputs": [],
   "source": [
    "# Q-network, an approximation of a Q-value function, Q(s, a)\n",
    "class QNetwork(nn.Module):\n",
    "  \n",
    "  def __init__(self, observation_space, action_space):\n",
    "    super().__init__()\n",
    "\n",
    "    self._action_space = action_space\n",
    "    self._eps = 1\n",
    "\n",
    "    # Input: observation\n",
    "    # Output: q-value for each action\n",
    "    self.fc = MLP(observation_space.shape[0], action_space.n, [32, 32])\n",
    "    print(self.fc)\n",
    "    \n",
    "  def forward(self, observation):\n",
    "    q_values = self.fc(observation)\n",
    "    return q_values\n",
    "  \n",
    "  def act(self, observation, is_train=True):\n",
    "    # Epsilon greedy for exploration\n",
    "    if is_train and np.random.uniform() < self._eps:\n",
    "      action = self._action_space.sample()\n",
    "    else:\n",
    "      # Observation is numpy ndarray\n",
    "      # Convert numpy array to tensor\n",
    "      obs = torch.tensor([observation]).to(device, dtype=torch.float32)\n",
    "      \n",
    "      # Compute q-values\n",
    "      q_values = self.forward(obs)\n",
    "      q_values = q_values.detach().cpu().numpy().squeeze()\n",
    "      \n",
    "      # Take an action with maximum value\n",
    "      action = np.argmax(q_values)\n",
    "    \n",
    "    return action\n",
    "  \n",
    "  def epsilon_decay(self):\n",
    "    self._eps -= 0.01\n",
    "    self._eps = max(self._eps, 0.01)\n",
    "    \n",
    "  def state_dict(self):\n",
    "    state_dict = super().state_dict()\n",
    "    state_dict['eps'] = self._eps\n",
    "    return state_dict\n",
    "  \n",
    "  def load_state_dict(self, state_dict):\n",
    "    self._eps = state_dict['eps']\n",
    "    state_dict.pop('eps')\n",
    "    super().load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ijX2c6iOXME"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "  def __init__(self, env, model, dataset):\n",
    "    self._env = env\n",
    "    self._model = model\n",
    "    self._dataset = dataset\n",
    "    self._logger = Logger()\n",
    "    \n",
    "    self._optim = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "  def run_one_episode(self, env, is_train=True):\n",
    "    model = self._model\n",
    "    dataset = self._dataset\n",
    "    \n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "      \n",
    "      # Sample an action\n",
    "      action = model.act(observation, is_train)\n",
    "      \n",
    "      # Take a step\n",
    "      observation_next, reward, done, info = env.step(action)\n",
    "      \n",
    "      # Add a transition to the dataset\n",
    "      dataset.store(observation, action, observation_next, reward, done)\n",
    "      observation = observation_next\n",
    "      \n",
    "      episode_length += 1\n",
    "      episode_reward += reward\n",
    "      \n",
    "      # Train q-network\n",
    "      if is_train:\n",
    "        batch = dataset.sample(batch_size=20)\n",
    "        loss = self._update(batch)\n",
    "        model.epsilon_decay()\n",
    "        \n",
    "        self._logger.add({'loss': loss})\n",
    "        self._logger.add({'action': action})\n",
    "      \n",
    "    if is_train:\n",
    "      self._logger.add({'length': episode_length, 'reward': episode_reward})  \n",
    "    else:\n",
    "      print('reward: {}'.format(episode_reward))\n",
    "          \n",
    "  def _update(self, batch):\n",
    "    batch_size = len(batch['obs'])\n",
    "    \n",
    "    obs = torch.tensor(batch['obs'], dtype=torch.float32)\n",
    "    obs_next = torch.tensor(batch['obs_next'], dtype=torch.float32)\n",
    "    rew = torch.tensor(batch['reward'], dtype=torch.float32).reshape(batch_size, 1)\n",
    "    ac = torch.eye(self._env.action_space.n)[batch['action']]\n",
    "    done = torch.tensor(batch['done'], dtype=torch.float32).reshape(batch_size, 1)\n",
    "    \n",
    "    discount_factor = 0.95\n",
    "    \n",
    "    # y\n",
    "    with torch.no_grad():\n",
    "      q_next = self._model(obs_next).max(dim=1, keepdim=True)[0]\n",
    "      \n",
    "      q_target = rew + (1 - done) * discount_factor * q_next\n",
    "    \n",
    "    # Q(s,a)\n",
    "    q_predict = torch.sum(self._model(obs) * ac, dim=1, keepdim=True)    \n",
    "    \n",
    "    # Mean square error\n",
    "    loss = (q_predict - q_target).pow(2).mean()\n",
    "    \n",
    "    # Backpropagation\n",
    "    self._optim.zero_grad()\n",
    "    loss.backward()\n",
    "    self._optim.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    \n",
    "  def train(self):\n",
    "    num_episode = 200\n",
    "    for i in range(num_episode):\n",
    "      self.run_one_episode(env=self._env, is_train=True)\n",
    "      \n",
    "      if (i + 1) % 10 == 0:\n",
    "        print('training episode {}/{}'.format(i + 1, num_episode))\n",
    "        self._logger.summary()\n",
    "\n",
    "  def evaluate(self):\n",
    "    env_test = wrap_env(gym.make('CartPole-v0'))\n",
    "    for i in range(10):\n",
    "      self.run_one_episode(env=env_test, is_train=False)\n",
    "    env_test.close()\n",
    "    show_video()\n",
    "    \n",
    "  def plot(self, key):\n",
    "    self._logger.plot(key)\n",
    "    \n",
    "  def state_dict(self):\n",
    "    return {'optim': self._optim.state_dict()}\n",
    "  \n",
    "  def load_state_dict(self, state_dict):\n",
    "    self._optim.load_state_dict(state_dict['optim'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lCR4K6sfM262",
    "outputId": "d6002166-2b43-492b-86df-b46cfb632172"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0b8785eb90>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure setting up random seeds before training\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "URKNQPUjSaSK",
    "outputId": "7f653bdb-fc85-443e-8604-34012c830c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "QNetwork(\n",
      "  (fc): MLP(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(123)\n",
    "\n",
    "# Model\n",
    "policy = QNetwork(env.observation_space, env.action_space)\n",
    "print(policy)\n",
    "\n",
    "# Dataset\n",
    "dataset = Dataset(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "colab_type": "code",
    "id": "XmZy2tyd0tkA",
    "outputId": "941d1197-4f40-4dbc-aa5f-aea6a5b4bfb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episode 10/200\n",
      "loss: 1.34, action: 0.80, length: 11.90, reward: 11.90\n",
      "training episode 20/200\n",
      "loss: 5.13, action: 0.63, length: 10.10, reward: 10.10\n",
      "training episode 30/200\n",
      "loss: 4.77, action: 0.89, length: 10.20, reward: 10.20\n",
      "training episode 40/200\n",
      "loss: 3.20, action: 0.79, length: 9.90, reward: 9.90\n",
      "training episode 50/200\n",
      "loss: 2.13, action: 0.57, length: 15.70, reward: 15.70\n",
      "training episode 60/200\n",
      "loss: 2.66, action: 0.27, length: 14.80, reward: 14.80\n",
      "training episode 70/200\n",
      "loss: 2.38, action: 0.45, length: 33.30, reward: 33.30\n",
      "training episode 80/200\n",
      "loss: 4.11, action: 0.50, length: 26.30, reward: 26.30\n",
      "training episode 90/200\n",
      "loss: 4.40, action: 0.50, length: 30.30, reward: 30.30\n",
      "training episode 100/200\n",
      "loss: 3.79, action: 0.50, length: 61.00, reward: 61.00\n",
      "training episode 110/200\n",
      "loss: 2.62, action: 0.53, length: 89.20, reward: 89.20\n",
      "training episode 120/200\n",
      "loss: 1.90, action: 0.52, length: 159.20, reward: 159.20\n",
      "training episode 130/200\n",
      "loss: 1.69, action: 0.52, length: 182.60, reward: 182.60\n",
      "training episode 140/200\n",
      "loss: 1.81, action: 0.52, length: 194.50, reward: 194.50\n",
      "training episode 150/200\n",
      "loss: 1.73, action: 0.52, length: 188.10, reward: 188.10\n",
      "training episode 160/200\n",
      "loss: 1.57, action: 0.52, length: 196.60, reward: 196.60\n",
      "training episode 170/200\n",
      "loss: 1.49, action: 0.53, length: 186.50, reward: 186.50\n",
      "training episode 180/200\n",
      "loss: 1.38, action: 0.53, length: 188.00, reward: 188.00\n",
      "training episode 190/200\n",
      "loss: 1.43, action: 0.53, length: 183.90, reward: 183.90\n",
      "training episode 200/200\n",
      "loss: 1.42, action: 0.54, length: 176.60, reward: 176.60\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAELCAYAAAA/cjqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgiRwqQJCCFECvsvVu/8YIWb58IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(env, policy, dataset)\n",
    "\n",
    "# Train Q-Network\n",
    "policy.train()\n",
    "trainer.train()\n",
    "\n",
    "trainer.plot('reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clm_5tH91QJ_"
   },
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "os.makedirs('ckpt', exist_ok=True)\n",
    "ckpt_path = os.path.join('ckpt', 'ckpt.pt')\n",
    "\n",
    "# Get parameters from models and optimizers\n",
    "state_dict = {}\n",
    "state_dict['trainer'] = trainer.state_dict()\n",
    "state_dict['policy'] = policy.state_dict()\n",
    "\n",
    "torch.save(state_dict, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Btv-MRUx1dmq"
   },
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "# Update parameters with checkpoint\n",
    "trainer.load_state_dict(ckpt['trainer'])\n",
    "policy.load_state_dict(ckpt['policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "ruzW9OIvJ6UO",
    "outputId": "74d48f52-086d-4719-9f77-345f72630907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 174.0\n",
      "reward: 181.0\n",
      "reward: 185.0\n",
      "reward: 171.0\n",
      "reward: 200.0\n",
      "reward: 194.0\n",
      "reward: 198.0\n",
      "reward: 173.0\n",
      "reward: 177.0\n",
      "reward: 195.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" autoplay \n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run evaluation\n",
    "policy.eval()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYXMa3Haeyxv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CSCI566_Intro_PyTorch (coding).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
